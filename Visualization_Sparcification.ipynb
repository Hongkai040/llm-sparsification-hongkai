{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2169,"status":"ok","timestamp":1668329307127,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"7oPVtnn-lnab","outputId":"39a7222e-f692-4527-c438-fd3558826378"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import os\n","os.chdir(\"/content/drive/MyDrive/Colab Notebooks\")"]},{"cell_type":"code","source":["!pip install -q transformers\n","import transformers \n","from transformers import GPT2Model, GPT2Tokenizer \n","from transformers import TextGenerationPipeline, AutoTokenizer, AutoModelForCausalLM \n","from transformers import MegatronBertConfig, MegatronBertModel, BertTokenizer \n","\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from torch import nn\n","import torch.nn.utils.prune as prune\n","import torch.nn.functional as F\n","\n","import copy\n","import json"],"metadata":{"id":"2G17eyXtCVbq","executionInfo":{"status":"ok","timestamp":1668329326841,"user_tz":360,"elapsed":16977,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# Models\n","\n","* GPT2-XL 1.5B(Decoder-only)\n","* Pangu $\\alpha$ 2.6B: [Intro from Huawei](https://www.huaweicloud.com/product/modelarts/pangu.html) \n","* erlangshen 1.3B: [Intro from IDEA](https://huggingface.co/IDEA-CCNL/Erlangshen-MegatronBert-1.3B)"],"metadata":{"id":"P8j3_MjyJpxN"}},{"cell_type":"markdown","metadata":{"id":"cZXpn0yMslTa"},"source":["# Visualization & Sparsification\n"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":537,"status":"ok","timestamp":1668329797751,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"},"user_tz":360},"id":"g1_Ucza6pE61"},"outputs":[],"source":["def get_params_plot(model, model_name, sparsity=0):\n","  # get params dist.\n","  fig, ax = plt.subplots(figsize=(12,8))\n","  total_param = torch.cat([params.flatten() for params in model.parameters()]).detach().numpy()\n","  hist, bins = np.histogram(total_param, bins = np.linspace(-1,1,201)) \n","  ax.plot(bins[:-1],hist) \n","  plt.title(\"distribution of all weights(model:{}, sparsity:{}%)\".format(model_name, sparsity*100), fontsize=25)\n","  plt.xlabel(\"Weight values\")\n","  plt.ylabel(\"Log Count\")\n","  plt.yscale('log')\n","  plt.show()\n","  plt.savefig('{}/figs/vis_all_params_{}_sparsity_{}%.png'.format(os.getcwd(), model_name, sparsity))\n","\n","  if model_name == 'pangu':\n","    for child in model.named_children():\n","      if child[0] == 'transformer':\n","        model = child[1]\n","  \n","  if model_name == 'erlangshen':\n","    for child in model.named_children():\n","      if child[0] == 'encoder':\n","        model = child[1]\n","  \n","  # get params dist. in each layer\n","  for elem in model.named_children():\n","    if elem[0] == 'h' or elem[0] == 'layer': # erlangshen model uses layer as attr name ...\n","      fig, ax = plt.subplots(figsize=(12,8))\n","      for idx, child in enumerate(elem[1].named_children()):\n","        layer_param = torch.cat([params.flatten() for params in child[1].parameters()]).detach().numpy()\n","        hist, bins = np.histogram(layer_param, bins = np.linspace(-1,1,201)) \n","        ax.plot(bins[:-1],hist,label=\"{} hidden layer\".format(idx)) \n","      plt.title(\"distribution of weights across layers(model:{}, sparsity:{}%)\".format(model_name, sparsity*100), fontsize=25)\n","      plt.xlabel(\"Weight values\")\n","      plt.ylabel(\"Log Count\")\n","      plt.yscale('log')\n","      plt.legend(loc=\"upper left\", bbox_to_anchor=(1, 1))\n","      plt.show()\n","      plt.savefig('{}/figs/vis_layers_params_{}_sparsity_{}%.png'.format(os.getcwd(), model_name, sparsity))"]},{"cell_type":"code","source":["def prune_model(model, model_name, prune_portion):\n","  '''\n","  using global pruning to prune gpt2, pangu, and erlangshen. \n","  '''\n","  def print_sparsity(module_lst, prune_flag):\n","\n","    zero_params_count = sum([torch.sum(module[0].weight == 0) for module in module_lst])\n","    total_params_count = sum([module[0].weight.nelement() for module in module_lst])\n","\n","    print(\n","        \"Global sparsity of model: {} in hidden layers {} pruning: {:.2f}%\".format(model_name, prune_flag,\n","                                                    100. * float(zero_params_count)\n","                                                        / float(total_params_count)\n","                                                    )\n","        )\n","    return None\n","    \n","  if model_name == 'pangu':\n","    modules = model.transformer.h.modules()\n","  elif model_name == 'erlangshen':\n","    modules = model.encoder.layer.modules()\n","  else:\n","    modules = model.h.modules()\n","\n","  module_lst = []\n","  for module in modules:\n","    if hasattr(module, 'weight'):\n","      module_lst.append((module, 'weight'))\n","\n","  print_sparsity(module_lst, prune_flag = 'before')\n","  prune.global_unstructured(module_lst, \n","                            pruning_method=prune.L1Unstructured, \n","                            amount=prune_portion)\n","  for module, attr in module_lst: \n","    prune.remove(module, attr)\n","  print_sparsity(module_lst, prune_flag = 'after')\n","  return model"],"metadata":{"id":"QIxb9uQYKHVb","executionInfo":{"status":"ok","timestamp":1668329611215,"user_tz":360,"elapsed":527,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Method from https://discuss.pytorch.org/t/finding-model-size/130275/5\n","def get_model_size(model):\n","  param_size = 0\n","  for param in model.parameters():\n","      param_size += param.nelement() * param.element_size()\n","  buffer_size = 0\n","  for buffer in model.buffers():\n","      buffer_size += buffer.nelement() * buffer.element_size()\n","\n","  size_all_mb = (param_size + buffer_size) / 1024**2\n","  print('model size: {:.3f}MB'.format(size_all_mb))\n","  return size_all_mb"],"metadata":{"id":"lO9fLC5JOiE4","executionInfo":{"status":"ok","timestamp":1668330203233,"user_tz":360,"elapsed":266,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["# gpt2 = GPT2Model.from_pretrained('gpt2-xl')\n","# pangu = AutoModelForCausalLM.from_pretrained(\"imone/pangu_2_6B\", trust_remote_code=True)\n","# erlangshen = MegatronBertModel.from_pretrained(\"IDEA-CCNL/Erlangshen-MegatronBert-1.3B\")\n","\n","# model_names = ['GPT2-xl', 'pangu', 'erlangshen']\n","# model_lst = [gpt2, pangu, erlangshen]\n","\n","gpt2 = GPT2Model.from_pretrained('gpt2')\n","model_names = ['GPT2-xl']\n","model_lst = [gpt2]\n","\n","sparsity = [0, 0.1, 0.5, 0.9, 0.95, 0.99] \n","\n","model_size_dic = dict()\n","\n","print(\"Start sparsifying...\")\n","for model, model_name in zip(model_lst, model_names):\n","  for prune_proportion in sparsity:\n","    target_model = copy.deepcopy(model)\n","    if sparsity != 0:\n","      target_model = prune_model(target_model, model_name, prune_proportion)\n","    model_size_dic[f'{model_name}_sparsity_{prune_proportion*100}%'] = get_model_size(target_model)\n","    get_params_plot(target_model, model_name, prune_proportion)\n","    target_model.save_pretrained(\"{}/models/{}_sparsity_{}\".format(os.getcwd(), \n","                                                            model_name,\n","                                                            prune_proportion*100,\n","                                                            ))\n","    print(\"model {} with sparsity {} saved\".format(model_name, prune_proportion * 100))\n","    \n","print(\"Sparsification completed!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"UxX2u0I9JcD1","executionInfo":{"status":"error","timestamp":1668330620532,"user_tz":360,"elapsed":5439,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"}},"outputId":"e49db044-e7e7-4897-f62d-b80aa9f0a682"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Start sparsifying...\n","Global sparsity of model: before in hidden layers GPT2-xl pruning: 0.00%\n","Global sparsity of model: after in hidden layers GPT2-xl pruning: 0.00%\n","model size: 486.700MB\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-00c3c699aecd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0mtarget_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprune_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_proportion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmodel_size_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'{model_name}_sparsity_{sparsity*100}%'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mget_params_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprune_proportion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     target_model.save_pretrained(\"{}/models/{}_sparsity_{}\".format(os.getcwd(), \n\u001b[1;32m     25\u001b[0m                                                             \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-9-40ef5f016e36>\u001b[0m in \u001b[0;36mget_params_plot\u001b[0;34m(model, model_name, sparsity)\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtotal_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mhist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistogram\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_param\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m201\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distribution of all weights(model:{}, sparsity:{}%)\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparsity\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfontsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/histograms.py\u001b[0m in \u001b[0;36mhistogram\u001b[0;34m(a, bins, range, normed, weights, density)\u001b[0m\n\u001b[1;32m    876\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBLOCK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m                 \u001b[0msa\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mBLOCK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m                 \u001b[0mcum_n\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0m_search_sorted_inclusive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbin_edges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msort\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m    996\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 998\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    999\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]},{"output_type":"display_data","data":{"text/plain":["<Figure size 864x576 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["dir_open = open(f'{os.getcwd()}/model_size.json', \"w\")\n","json.dump(model_size_dic, dir_open, indent = 4)"],"metadata":{"id":"N7Akb58QQL2k","executionInfo":{"status":"ok","timestamp":1668330996995,"user_tz":360,"elapsed":2,"user":{"displayName":"Shiba Mao","userId":"16549320756357564965"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WdqtAke1m8hH"},"outputs":[],"source":["# tokenizer = BertTokenizer.from_pretrained(\"IDEA-CCNL/Erlangshen-MegatronBert-1.3B\")\n","# config = MegatronBertConfig.from_pretrained(\"IDEA-CCNL/Erlangshen-MegatronBert-1.3B\")"]},{"cell_type":"markdown","metadata":{"id":"0YTSG70TmFWR"},"source":["# Evaluation on Benchmarks\n","\n","For GPT2: XNLI and CLM\n","\n","For pangu, erlangshen: XNLI and CLUE"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5RCg3E5lmI4R"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"machine_shape":"hm","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}